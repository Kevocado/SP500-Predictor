"""
Background Scanner â€” Multi-Engine Compute-on-Write
Runs from GitHub Actions (or locally). Executes Weather + Macro engines first (real edge),
then Quant engine (paper trading). All real-edge ops go through AI Validator.

ARCHITECTURE:
  Tier 1 (Real Edge): Weather Engine + Macro Engine â†’ AI Validator â†’ LiveOpportunities table
  Tier 2 (Paper):     Quant Engine â†’ PaperTradingSignals table (no AI validation)
"""

import os
import sys
import re
import json
from datetime import datetime, timezone
from dotenv import load_dotenv

# Add project root to path so we can import src modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from azure.data.tables import TableClient
from azure.storage.blob import BlobServiceClient

from scripts.engines.weather_engine import WeatherEngine
from scripts.engines.macro_engine import MacroEngine
from scripts.engines.tsa_engine import TSAEngine
from scripts.engines.eia_engine import EIAEngine
from src.data_loader import fetch_data
from src.feature_engineering import create_features
from src.discord_notifier import DiscordNotifier
from scripts.engines.quant_engine import (
    load_model,
    predict_next_hour,
    calculate_probability,
    get_market_volatility,
    kelly_criterion,
)
from src.kalshi_feed import get_real_kalshi_markets
from src.ai_validator import AIValidator
import pandas as pd

# â”€â”€â”€ Environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
CONN_STR = os.getenv("AZURE_CONNECTION_STRING")

if not CONN_STR:
    print("âŒ AZURE_CONNECTION_STRING not set. Exiting.")
    sys.exit(1)

EDGE_THRESHOLD = 5.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIER 1: REAL EDGE â€” Weather + Macro
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def scan_real_edge():
    """
    Run Weather and Macro engines.
    Returns raw math-based opportunities (NO AI validation â€” that's on-demand in UI).
    """
    all_ops = []

    # â”€â”€ Weather Engine (fetches KXHIGHNY, KXHIGHCHI, KXHIGHMIA) â”€â”€
    print("\nâ›ˆï¸ Running Weather Engine...")
    try:
        weather_engine = WeatherEngine()
        weather_ops = weather_engine.find_opportunities()
        print(f"  Found {len(weather_ops)} weather opportunities")
        all_ops.extend(weather_ops)
    except Exception as e:
        print(f"  âš ï¸ Weather Engine failed: {e}")

    # â”€â”€ Macro Engine (fetches KXLCPIMAXYOY, KXFED, KXGDPYEAR, etc) â”€â”€
    print("\nğŸ›ï¸ Running Macro Engine...")
    try:
        macro_engine = MacroEngine()
        macro_ops = macro_engine.find_opportunities()
        print(f"  Found {len(macro_ops)} macro opportunities")
        all_ops.extend(macro_ops)
    except Exception as e:
        print(f"  âš ï¸ Macro Engine failed: {e}")

    # â”€â”€ TSA Travel Engine (TSA Passenger Volumes) â”€â”€
    print("\nâœˆï¸ Running TSA Engine...")
    try:
        tsa_engine = TSAEngine()
        tsa_ops = tsa_engine.find_opportunities()
        print(f"  Found {len(tsa_ops)} TSA opportunities")
        all_ops.extend(tsa_ops)
    except Exception as e:
        print(f"  âš ï¸ TSA Engine failed: {e}")

    # â”€â”€ EIA Energy Engine (Natural Gas / Crude Storage) â”€â”€
    print("\nâ›½ Running EIA Engine...")
    try:
        eia_engine = EIAEngine()
        eia_ops = eia_engine.find_opportunities()
        print(f"  Found {len(eia_ops)} EIA opportunities")
        all_ops.extend(eia_ops)
    except Exception as e:
        print(f"  âš ï¸ EIA Engine failed: {e}")

    print(f"\nğŸ“Š Total real-edge opportunities: {len(all_ops)} (AI validation available on-demand in UI)")
    return all_ops


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIER 2: PAPER TRADING â€” Quant ML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def scan_quant_ml():
    """
    Quant ML scanner for SPX/Nasdaq/BTC/ETH.
    Returns (snapshot_records, paper_opportunities).
    âš ï¸ PAPER TRADING ONLY - no AI validation needed.
    """
    tickers = ["SPX", "Nasdaq", "BTC", "ETH"]
    snapshot_records = []
    paper_opportunities = []

    data_cache = {}
    for ticker in tickers:
        try:
            df = fetch_data(ticker, period="5d", interval="1h")
            model, needs_retrain = load_model(ticker)

            if model and not df.empty:
                df_feat = create_features(df)
                pred_val = predict_next_hour(model, df_feat, ticker)
                curr_price = df['Close'].iloc[-1]
                vol = get_market_volatility(df, window=24)

                data_cache[ticker] = {
                    "df": df, "model": model, "vol": vol,
                    "price": curr_price, "pred": pred_val,
                }
                print(f"    âœ… {ticker}: Price={curr_price:.2f}, Pred={pred_val:.2f}, Vol={vol:.6f}")
        except Exception as e:
            print(f"    âš ï¸ Skipping {ticker}: {e}")

    for ticker in tickers:
        if ticker not in data_cache:
            continue

        d = data_cache[ticker]
        markets, method, debug = get_real_kalshi_markets(ticker)
        print(f"    ğŸ“¡ {ticker}: {len(markets)} markets via {method}")

        for m in markets:
            try:
                strike_match = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?)', m.get('title', ''))
                if not strike_match:
                    continue
                strike = float(strike_match.group(1).replace(',', ''))
            except Exception:
                continue

            hours_left = 1.0
            exp_str = m.get('expiration')
            if exp_str:
                try:
                    exp = pd.to_datetime(exp_str)
                    if exp.tzinfo is None:
                        exp = exp.replace(tzinfo=timezone.utc)
                    hours_left = max(0.1, (exp - datetime.now(timezone.utc)).total_seconds() / 3600)
                except Exception:
                    pass

            title = m.get('title', '')
            is_above = ">" in title or "above" in title.lower()
            my_prob = calculate_probability(d['price'], d['pred'], strike, d['vol'], hours_left)
            if not is_above:
                my_prob = 100 - my_prob

            yes_ask = m.get('yes_ask', 0)
            edge = my_prob - yes_ask
            bet_size = kelly_criterion(my_prob, yes_ask, bankroll=20, fractional=0.25)

            record = {
                "ticker": ticker, "market_title": title,
                "market_id": m.get('market_id', ''), "strike": strike,
                "expiration": exp_str, "current_price": round(d['price'], 2),
                "model_pred": round(d['pred'], 2), "volatility": round(d['vol'], 6),
                "hours_left": round(hours_left, 1), "model_prob": round(my_prob, 2),
                "market_yes_ask": yes_ask, "calculated_edge": round(edge, 2),
                "kelly_bet": round(bet_size, 2),
            }
            snapshot_records.append(record)

            if abs(edge) > EDGE_THRESHOLD and bet_size > 0:
                action = "BUY YES" if edge > 0 else "BUY NO"
                paper_opportunities.append({
                    "PartitionKey": "Paper",
                    "RowKey": f"{ticker}_{m.get('market_id', strike)}".replace(" ", ""),
                    "Asset": ticker, "Market": title[:200], "Strike": str(strike),
                    "Confidence": float(round(my_prob, 1)),
                    "Edge": float(round(edge, 1)), "Action": action,
                    "KellySuggestion": float(round(bet_size, 2)),
                    "CurrentPrice": float(round(d['price'], 2)),
                    "ModelPred": float(round(d['pred'], 2)),
                    "Volatility": float(round(d['vol'], 6)),
                    "HoursLeft": float(round(hours_left, 1)),
                    "MarketYesAsk": int(yes_ask),
                    "Expiration": exp_str or "",
                    "MarketId": m.get('market_id', ''),
                    "Status": "PAPER TRADE ONLY",
                    "Engine": "Quant",
                })

    return snapshot_records, paper_opportunities


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN ORCHESTRATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_scan():
    """Main scanning logic â€” prioritizes real edge markets."""
    now = datetime.now(timezone.utc)
    print(f"ğŸš€ Starting Multi-Engine Scan at {now.isoformat()}")

    # â”€â”€ Initialize Azure clients â”€â”€
    blob_service = BlobServiceClient.from_connection_string(CONN_STR)
    live_table = TableClient.from_connection_string(CONN_STR, "LiveOpportunities")
    paper_table = TableClient.from_connection_string(CONN_STR, "PaperTradingSignals")

    for table in [live_table, paper_table]:
        try:
            table.create_table()
        except Exception:
            pass
    try:
        blob_service.create_container("market-snapshots")
    except Exception:
        pass

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â• TIER 1: REAL EDGE â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Engines fetch their own Kalshi markets via series_ticker (fastest method)
    # AI validation is ON-DEMAND in the Streamlit UI (avoids rate limits)
    real_edge_ops = scan_real_edge()

    # â”€â”€ Discord Alerts (for high-conviction trades) â”€â”€
    try:
        notifier = DiscordNotifier()
        if notifier.is_enabled():
            notifier.send_alert(real_edge_ops, min_edge=30.0)
    except Exception as e:
        print(f"  âš ï¸ Discord alert failed: {e}")

def calculate_annualized_ev(edge_pct, expiration_str):
    """Calculates Annualized Expected Value."""
    try:
        now_dt = datetime.now(timezone.utc)
        if not expiration_str: return 0
        try:
            exp = pd.to_datetime(expiration_str)
            if exp.tzinfo is None: exp = exp.tz_localize('UTC')
        except Exception: return 0
        days_to_res = (exp - now_dt).days
        if days_to_res <= 0: days_to_res = 1
        return (edge_pct * 365) / days_to_res
    except Exception: return 0

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â• TIER 2: PAPER TRADING â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ§ª Running Quant Engine (Paper Trading)...")
    snapshot_records, paper_ops = scan_quant_ml()
    print(f"  Found {len(paper_ops)} quant signals (EDUCATIONAL ONLY)")

    # â”€â”€ Save snapshot to Blob â”€â”€
    full_snapshot = {
        "timestamp_utc": now.isoformat(),
        "markets_analyzed": len(snapshot_records),
        "live_opportunities": len(real_edge_ops),
        "paper_signals": len(paper_ops),
        "records": snapshot_records,
    }
    blob_name = f"snapshot_{now.strftime('%Y%m%d_%H%M%S')}.json"
    blob_client = blob_service.get_blob_client(container="market-snapshots", blob=blob_name)
    blob_client.upload_blob(json.dumps(full_snapshot, default=str), overwrite=True)
    print(f"\nâœ… Saved snapshot: {blob_name} ({len(snapshot_records)} markets)")

    # â”€â”€ Update LiveOpportunities table â”€â”€
    try:
        for e in live_table.query_entities("PartitionKey eq 'Live'"):
            live_table.delete_entity(e['PartitionKey'], e['RowKey'])
    except Exception:
        pass

    for opp in real_edge_ops:
        try:
            row_key = opp.get('market_ticker', f"{opp.get('engine', 'UNK')}_{opp.get('asset', 'UNK')}_{now.strftime('%H%M%S')}")
            row_key = row_key.replace('/', '_').replace('\\', '_').replace('#', '_').replace('?', '_')
            entity = {
                "PartitionKey": "Live",
                "RowKey": row_key,
                "Engine": opp.get('engine', ''),
                "Asset": opp.get('asset', ''),
                "Market": str(opp.get('market_title', ''))[:200],
                "Action": opp.get('action', ''),
                "Edge": float(opp.get('edge', 0)),
                "Confidence": float(opp.get('confidence', 0)),
                "Reasoning": str(opp.get('reasoning', ''))[:500],
                "DataSource": opp.get('data_source', ''),
                "AIValidated": False,  # On-demand in UI
                "KalshiUrl": opp.get('kalshi_url', ''),
                "MarketTicker": opp.get('market_ticker', ''),
                "MarketDate": opp.get('market_date', ''),
                "Expiration": opp.get('expiration', ''),
                "MarketPrice": float(opp.get('market_price', 0)),
                "ModelProb": float(opp.get('model_probability', 0)),
                "Spread": float(opp.get('spread', 5)), # Default to 5
                "AnnualizedEV": calculate_annualized_ev(float(opp.get('edge', 0)), opp.get('expiration', ''))
            }
            # Only save to Live if spread is reasonable (<20 cents, but we filter stricter in UI)
            if entity["Spread"] <= 20: 
                live_table.create_entity(entity)
        except Exception as e:
            print(f"  âš ï¸ Failed to save live op: {e}")

    print(f"âœ… Saved {len(real_edge_ops)} math-based opportunities to LiveOpportunities (AI on-demand in UI)")

    # â”€â”€ Update PaperTradingSignals table â”€â”€
    try:
        for e in paper_table.query_entities("PartitionKey eq 'Paper'"):
            paper_table.delete_entity(e['PartitionKey'], e['RowKey'])
    except Exception:
        pass

    for op in paper_ops:
        try:
            paper_table.create_entity(op)
        except Exception as e:
            print(f"  âš ï¸ Failed to save paper op: {e}")

    print(f"âœ… Saved {len(paper_ops)} quant signals to PaperTradingSignals")

    print(f"\nğŸ Scan complete at {datetime.now(timezone.utc).isoformat()}")


if __name__ == "__main__":
    run_scan()

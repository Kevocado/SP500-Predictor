This is the perfect tech stack for this rebuild. Using Antigravity (for visual architecture and Streamlit UI design) alongside Claude Code (for deep Python refactoring and complex API integration) allows you to move incredibly fast.

Here is your step-by-step master plan, including the exact prompts to feed into each tool to execute the "Final Specs" architecture.

Phase 1: Architectural Scaffolding (Use Antigravity)
Antigravity is highly effective at big-picture restructuring and UI design. Let it build the new skeleton and update the Streamlit dashboard to reflect the pivot.

Open your project in Antigravity and use this prompt:

"I am rebuilding this project to be a multi-engine prediction market system.

Create a new directory structure: move src/model.py and src/signals.py into a new folder called scripts/engines/. Rename them to quant_engine.py (which will be strictly for paper trading) and create empty placeholder files for weather_engine.py and macro_engine.py.

Refactor streamlit_app.py. Remove all the live calculation logic. The UI should now just read from Azure Table Storage.

Redesign the Streamlit tabs. Tab 1 should be 'Real Edge (Live)' showing high-conviction Weather and Macro trades. Tab 2 should be 'Quant Lab (Paper Trading)' showing the SPX/BTC algorithmic predictions."

Phase 2: The Alpaca Migration (Use Claude Code)
Now, switch to your terminal. Claude 3.7 (via Claude Code) is unparalleled at ripping out old libraries and safely wiring up new ones.

In your terminal, run claude and paste this:

"Read src/data_loader.py and scripts/engines/quant_engine.py. We are completely removing yfinance and replacing it with the alpaca-py SDK for institutional-grade data.

Rewrite fetch_data() to pull historical minute-bar data using Alpaca's StockHistoricalDataClient and CryptoHistoricalDataClient.

Ensure the returned DataFrame exactly matches the schema expected by create_features() (Open, High, Low, Close, Volume).

Update requirements.txt to remove yfinance and add alpaca-py.

Ensure the Quant Engine is explicitly labeled in its outputs as 'PAPER TRADE ONLY'."

Phase 3: Building the "Real Edge" Engines (Use Claude Code)
This is where you build the fundamentally driven models for the markets where public data actually provides an advantage.

In Claude Code, use this prompt:

"I need to build scripts/engines/macro_engine.py and scripts/engines/weather_engine.py.

For macro_engine.py: Write a script that uses the fredapi to fetch the latest US Core CPI and 10-Year Treasury Yields. It should map these metrics against open Kalshi economic markets to find statistical mispricings.

For weather_engine.py: Write a script that hits the public NOAA API to get the 7-day temperature forecast for New York and Chicago, and compares it against Kalshi's daily high-temperature markets.

Both scripts must format their 'found opportunities' as dictionaries compatible with our Azure Table Storage schema, but only flag them if the calculated edge is > 5%."

Phase 4: The LLM "Scrutinizer" (Use Claude Code)
To fulfill your requirement of "only identifying real edge," you must stop relying purely on math arrays and add an AI reasoning step. Claude Code can wire up the Gemini Pro API (since you have the subscription) to act as your final filter.

In Claude Code, use this prompt:

"Read the output logic of our new engines. I want to add an AI Scrutinizer step before anything is saved to Azure Table Storage for the UI.

Create src/ai_validator.py.

Write a function that takes the mathematical 'edge' calculated by the Macro or Weather engine, and sends a prompt to the google-generativeai (Gemini) API.

The prompt must ask Gemini to scrutinize the trade: 'Is this mathematical edge real, or is the market pricing in a qualitative event (like a sudden news break or unseasonable weather front) that the historical math missed?'

The function should return a boolean (True if Gemini approves the trade, False if it detects a value trap) and a short 'Reasoning' string.

Integrate this validator into the background scanner so the UI only displays AI-approved trades."

How to Manage the Workflow
Iterate in the Terminal: Let Claude Code run the tests. If it hits an Alpaca API error, just type "Fix the Alpaca authentication error" and let it read the stack trace autonomously.

Review in Antigravity: When Claude Code finishes a major backend rewrite, open the Antigravity browser preview to ensure the Streamlit UI didn't break and is correctly displaying the new Reasoning fields generated by the AI Scrutinizer.

By isolating your complex modeling to the MSBA-level algorithmic work in the "Quant Lab" and using hard APIs (NOAA/FRED) for live capital, you create a system that is incredibly robust for backtesting while staying mathematically grounded for live execution.